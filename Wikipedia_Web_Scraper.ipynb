{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIuPDjsQnGTDaVF1FmwSke",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KathituCodes/Wikipedia-Scraper/blob/main/Wikipedia_Web_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Function to get and parse HTML content\n",
        "def get_html_content(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return BeautifulSoup(response.content, 'html.parser')\n",
        "    else:\n",
        "        raise Exception(f\"Failed to retrieve content. Status code: {response.status_code}\")\n",
        "\n",
        "# Function to extract article title\n",
        "def extract_article_title(soup):\n",
        "    title = soup.find(\"h1\", {\"id\": \"firstHeading\"}).text\n",
        "    return title\n",
        "\n",
        "# Function to extract article text with headings\n",
        "def extract_article_text(soup):\n",
        "    content = {}\n",
        "    for heading in soup.find_all(['h2', 'h3']):\n",
        "        heading_text = heading.get_text(strip=True)\n",
        "        content[heading_text] = []\n",
        "        for sibling in heading.find_next_siblings():\n",
        "            if sibling.name == 'h2' or sibling.name == 'h3':\n",
        "                break\n",
        "            if sibling.name == 'p':\n",
        "                content[heading_text].append(sibling.get_text(strip=True))\n",
        "    return content\n",
        "\n",
        "# Function to collect links redirecting to Wikipedia pages\n",
        "def collect_wikipedia_links(soup):\n",
        "    links = set()\n",
        "    for a in soup.find_all('a', href=True):\n",
        "        href = a['href']\n",
        "        if href.startswith('/wiki/') and ':' not in href:\n",
        "            links.add(f\"https://en.wikipedia.org{href}\")\n",
        "    return links\n",
        "\n",
        "# Function to scrape Wikipedia page and produce detailed output\n",
        "def scrape_wikipedia_page(url):\n",
        "    soup = get_html_content(url)\n",
        "\n",
        "    title = extract_article_title(soup)\n",
        "    content = extract_article_text(soup)\n",
        "    links = collect_wikipedia_links(soup)\n",
        "\n",
        "    # Number of sections\n",
        "    sections = list(content.keys())\n",
        "    num_sections = len(sections)\n",
        "\n",
        "    # First 3 sections\n",
        "    first_3_sections = sections[:3]\n",
        "\n",
        "    # First paragraph of the first section\n",
        "    first_section = sections[0] if sections else None\n",
        "    first_paragraph = content[first_section][0] if first_section and content[first_section] else None\n",
        "\n",
        "    # Number of Wikipedia links\n",
        "    num_links = len(links)\n",
        "\n",
        "    # First 5 Wikipedia links\n",
        "    first_5_links = list(links)[:5]\n",
        "\n",
        "    # Print detailed output\n",
        "    print(f\"Title: {title}\")\n",
        "    print(f\"Number of sections: {num_sections}\")\n",
        "    print(f\"First 3 sections: {first_3_sections}\")\n",
        "    print(f\"First paragraph of {first_section}:\")\n",
        "    if first_paragraph:\n",
        "        print(first_paragraph)\n",
        "    else:\n",
        "        print(\"No paragraphs found.\")\n",
        "    print(f\"Number of Wikipedia links: {num_links}\")\n",
        "    print(f\"First 5 Wikipedia links:\")\n",
        "    for link in first_5_links:\n",
        "        print(link)\n",
        "\n",
        "    return {\n",
        "        \"title\": title,\n",
        "        \"num_sections\": num_sections,\n",
        "        \"first_3_sections\": first_3_sections,\n",
        "        \"first_paragraph\": first_paragraph,\n",
        "        \"num_links\": num_links,\n",
        "        \"first_5_links\": first_5_links\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    wikipedia_url = \"https://en.wikipedia.org/wiki/Python_(programming_language)\"  # Example page\n",
        "    data = scrape_wikipedia_page(wikipedia_url)\n",
        "    print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3-DgmjBvxUI",
        "outputId": "3b6dfdbc-a7a1-4a64-b9fe-a874099d4999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Python (programming language)\n",
            "Number of sections: 30\n",
            "First 3 sections: ['Contents', 'History', 'Design philosophy and features']\n",
            "First paragraph of Contents:\n",
            "No paragraphs found.\n",
            "Number of Wikipedia links: 843\n",
            "First 5 Wikipedia links:\n",
            "https://en.wikipedia.org/wiki/Autoregressive_model\n",
            "https://en.wikipedia.org/wiki/Speakeasy_(computational_environment)\n",
            "https://en.wikipedia.org/wiki/GPT-J\n",
            "https://en.wikipedia.org/wiki/Inductive_bias\n",
            "https://en.wikipedia.org/wiki/Open-source_software_security\n",
            "{'title': 'Python (programming language)', 'num_sections': 30, 'first_3_sections': ['Contents', 'History', 'Design philosophy and features'], 'first_paragraph': None, 'num_links': 843, 'first_5_links': ['https://en.wikipedia.org/wiki/Autoregressive_model', 'https://en.wikipedia.org/wiki/Speakeasy_(computational_environment)', 'https://en.wikipedia.org/wiki/GPT-J', 'https://en.wikipedia.org/wiki/Inductive_bias', 'https://en.wikipedia.org/wiki/Open-source_software_security']}\n"
          ]
        }
      ]
    }
  ]
}